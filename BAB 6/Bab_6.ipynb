{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Abi-Lowkey/Introduction-to-Machine-Learning-with-Python-Books/blob/main/BAB%206/Bab_6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Bab 6: Algorithm Chains and Pipelines**"
      ],
      "metadata": {
        "id": "Kr0AhpShgVjG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **1. Tujuan**  \n",
        "Bab ini menjelaskan cara merangkai berbagai langkah preprocessing data dan penerapan model machine learning ke dalam satu alur kerja terintegrasi menggunakan **pipeline**. Dengan pipeline, seluruh proses mulai dari transformasi data hingga pelatihan model dapat dilakukan secara otomatis, konsisten, dan efisien. Hal ini tidak hanya menyederhanakan workflow, tetapi juga membantu mengurangi risiko kesalahan akibat langkah preprocessing yang terpisah-pisah atau tidak konsisten. Pipeline sangat berguna untuk mengelola data yang kompleks dan memungkinkan replikasi proses dengan mudah pada dataset baru."
      ],
      "metadata": {
        "id": "8ge08BW0gZoO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Implementasi Kode\n",
        "### 2.1 Membuat Pipeline"
      ],
      "metadata": {
        "id": "JSplWOcsgcnK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "# Membuat pipeline dengan scaler untuk normalisasi data dan SVM sebagai model klasifikasi\n",
        "pipeline = Pipeline([\n",
        "    ('scaler', StandardScaler()),  # Langkah pertama: Normalisasi data menggunakan StandardScaler\n",
        "    ('svm', SVC(kernel='linear'))  # Langkah kedua: Model SVM dengan kernel linear\n",
        "])\n",
        "\n",
        "# Data sederhana yang diubah dengan X berisi 2 fitur dan y berisi label kelas\n",
        "X = [[5.1, 3.5], [4.9, 3.0], [6.2, 2.8], [5.8, 2.7]]  # Contoh data fitur (misalnya panjang dan lebar sepal)\n",
        "y = [0, 0, 1, 1]  # Label kelas, di mana 0 dan 1 mewakili dua kategori\n",
        "\n",
        "# Melatih pipeline pada data X dan y\n",
        "pipeline.fit(X, y)  # Pipeline secara otomatis menjalankan scaler pada data sebelum melatih model\n",
        "print(\"Model berhasil dilatih dengan pipeline.\")  # Output bahwa pipeline telah berhasil dibuat dan digunakan\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "imfTPIzPgfjf",
        "outputId": "ed7eae7f-5c6b-448a-bbd4-68d69b4f2d85"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model berhasil dilatih dengan pipeline.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV  # Mengimpor GridSearchCV dari sklearn.model_selection untuk mencari kombinasi hyperparameter terbaik dengan cross-validation\n",
        "\n",
        "# Parameter grid untuk pipeline  # Mendefinisikan ruang pencarian untuk hyperparameter dalam pipeline\n",
        "param_grid = {\n",
        "    'svm__C': [0.1, 1, 10],  # Parameter C adalah parameter regularisasi dalam model SVM yang mengontrol kompleksitas model. Nilai kecil (misalnya 0.1) akan membuat model lebih sederhana, sementara nilai besar (misalnya 10) membuat model lebih kompleks.\n",
        "    'svm__gamma': [0.1, 1, 10]  # Parameter gamma mengontrol seberapa besar pengaruh data latih terhadap keputusan model. Nilai kecil (misalnya 0.1) memberikan pengaruh yang lebih luas, sedangkan nilai besar (misalnya 10) membuat model lebih sensitif terhadap data latih.\n",
        "}\n"
      ],
      "metadata": {
        "id": "tXg7kkFsghvK"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Grid search dengan pipeline  # Menggunakan GridSearchCV untuk mencari hyperparameter terbaik dalam pipeline dengan cross-validation\n",
        "grid = GridSearchCV(pipeline, param_grid, cv=2)  # Mengubah cv menjadi 2 atau lebih kecil dari jumlah sampel data\n",
        "grid.fit(X, y)  # Melatih grid search dengan data X dan target y untuk mencari kombinasi hyperparameter terbaik\n",
        "\n",
        "# Menampilkan hasil grid search  # Menampilkan parameter terbaik yang ditemukan dan skor cross-validation terbaik\n",
        "print(\"Best parameters:\", grid.best_params_)  # Mencetak parameter terbaik yang dipilih GridSearchCV\n",
        "print(\"Best cross-validation score:\", grid.best_score_)  # Mencetak skor validasi silang terbaik untuk parameter terbaik"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_jYVmajvgrPb",
        "outputId": "932cba94-8db5-4834-e233-392103f5dd6d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters: {'svm__C': 0.1, 'svm__gamma': 0.1}\n",
            "Best cross-validation score: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **3. Penjelasan Teoritis**\n",
        "- **Pipeline**: Merupakan konsep yang sangat berguna dalam machine learning karena memungkinkan untuk menggabungkan semua langkah yang diperlukan (seperti preprocessing, pemodelan, dan evaluasi) ke dalam satu objek yang terintegrasi. Hal ini memungkinkan kita untuk menjaga alur kerja tetap konsisten dan terstruktur. Dengan menggunakan pipeline, Anda dapat memastikan bahwa setiap langkah diproses dengan cara yang sama, baik pada data training maupun testing. Ini juga mengurangi kemungkinan terjadinya kebocoran data dari data testing ke data training, karena pipeline menangani proses-proses tersebut dengan urutan yang benar.\n",
        "  \n",
        "- **Parameter Grid dalam Pipeline**: Ketika menggunakan GridSearchCV dalam pipeline, kita harus menggunakan penamaan tahap untuk merujuk ke parameter model atau preprocessing yang ingin dicari nilainya. Misalnya, pada `svm__C` dan `svm__gamma`, \"svm\" merujuk pada tahap SVM dalam pipeline, dan `C` serta `gamma` adalah parameter dari model SVM yang ingin kita optimalkan. GridSearchCV secara otomatis akan mencoba berbagai kombinasi parameter yang kita tentukan dalam `param_grid` dan memilih yang terbaik berdasarkan evaluasi cross-validation.\n",
        "\n",
        "- **Keuntungan Pipeline**:\n",
        "  - **Mengurangi duplikasi kode**: Semua langkah, mulai dari preprocessing hingga modeling, dapat digabungkan dalam satu pipeline, mengurangi kebutuhan untuk menulis kode yang berulang untuk preprocessing data pada setiap langkah.\n",
        "  - **Memastikan data test tidak terkontaminasi preprocessing dari data training**: Salah satu risiko dalam machine learning adalah data test yang bisa saja terpengaruh oleh data training jika langkah preprocessing tidak dilakukan dengan benar. Pipeline memastikan bahwa data test tidak akan terpengaruh oleh proses preprocessing pada data training, sehingga model tetap dapat diuji dengan cara yang valid.\n",
        "\n",
        "## 4. Insight & Ringkasan\n",
        "- **Pipeline** mempermudah pengelolaan langkah preprocessing dan model dalam satu workflow, membuat seluruh proses menjadi lebih efisien dan terstruktur.\n",
        "- **Menggunakan GridSearch dengan pipeline** meningkatkan efisiensi dalam mencari hyperparameter terbaik karena GridSearchCV akan bekerja dengan baik di dalam pipeline, memanfaatkan evaluasi cross-validation secara otomatis.\n",
        "- Bab ini mengajarkan cara membangun alur kerja yang lebih bersih dan mudah untuk dikelola dalam proyek machine learning, di mana setiap tahap diatur dengan baik untuk menghasilkan model yang optimal dan terhindar dari kesalahan dalam pengolahan data."
      ],
      "metadata": {
        "id": "8aYPMeFkgxlF"
      }
    }
  ]
}